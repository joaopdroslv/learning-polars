{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "!pip install polars"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 1,
   "metadata": {},
   "outputs": [],
   "source": [
    "import polars as pl"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Optimizations and Performance in Polars\n",
    "\n",
    "Polars is built for high-performance data manipulation, leveraging parallelism and lazy execution. In this section, we'll cover:\n",
    "\n",
    "- LazyFrame vs. DataFrame: When to Use Each?\n",
    "- Parallel Execution and Automatic Optimizations\n",
    "- Working with Large Datasets (>1GB)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### 1. LazyFrame vs. DataFrame: When to Use Each?\n",
    "Polars offers two main data structures:\n",
    "\n",
    "1. `pl.DataFrame` (Eager Execution)\n",
    "- Similar to Pandas.\n",
    "- Executes operations immediately.\n",
    "- Best for small to medium datasets when quick results are needed.\n",
    "\n",
    "2. `pl.LazyFrame` (Lazy Execution)\n",
    "- Similar to SQL query planners.\n",
    "- Operations are deferred and optimized before execution.\n",
    "- Best for large datasets where performance matters."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 24,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Eager Execution:\n",
      " shape: (3, 2)\n",
      "â”Œâ”€â”€â”€â”€â”€â”¬â”€â”€â”€â”€â”€â”€â”€â”\n",
      "â”‚ id  â”† value â”‚\n",
      "â”‚ --- â”† ---   â”‚\n",
      "â”‚ i64 â”† i64   â”‚\n",
      "â•žâ•â•â•â•â•â•ªâ•â•â•â•â•â•â•â•¡\n",
      "â”‚ 3   â”† 30    â”‚\n",
      "â”‚ 4   â”† 40    â”‚\n",
      "â”‚ 5   â”† 50    â”‚\n",
      "â””â”€â”€â”€â”€â”€â”´â”€â”€â”€â”€â”€â”€â”€â”˜\n",
      "Lazy Execution (after collect()):\n",
      " shape: (3, 2)\n",
      "â”Œâ”€â”€â”€â”€â”€â”¬â”€â”€â”€â”€â”€â”€â”€â”\n",
      "â”‚ id  â”† value â”‚\n",
      "â”‚ --- â”† ---   â”‚\n",
      "â”‚ i64 â”† i64   â”‚\n",
      "â•žâ•â•â•â•â•â•ªâ•â•â•â•â•â•â•â•¡\n",
      "â”‚ 3   â”† 30    â”‚\n",
      "â”‚ 4   â”† 40    â”‚\n",
      "â”‚ 5   â”† 50    â”‚\n",
      "â””â”€â”€â”€â”€â”€â”´â”€â”€â”€â”€â”€â”€â”€â”˜\n"
     ]
    }
   ],
   "source": [
    "df = pl.DataFrame({\n",
    "    'id': [1, 2, 3, 4, 5],\n",
    "    'value': [10, 20, 30, 40, 50]\n",
    "})\n",
    "\n",
    "# Applying a filter (Eager execution - runs immediately)\n",
    "eager_result = df.filter(pl.col('value') > 20)\n",
    "\n",
    "print('Eager Execution:\\n', eager_result)\n",
    "\n",
    "# ----------\n",
    "\n",
    "# Sample LazyFrame (Lazy Execution)\n",
    "lf = df.lazy()\n",
    "\n",
    "# Applying a filter (Lazy execution - does not run immediately)\n",
    "lazy_result = lf.filter(pl.col('value') > 20)\n",
    "\n",
    "# Must call collect() to execute LazyFrame\n",
    "final_result = lazy_result.collect()\n",
    "\n",
    "print('Lazy Execution (after collect()):\\n', final_result)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### 2. Parallel Execution and Automatic Optimizations\n",
    "\n",
    "Polars is designed for multi-threading and automatically optimizes queries.\n",
    "\n",
    "**Polars' Optimization Techniques**\n",
    "- `Predicate Pushdown`: Filters are applied early to reduce computation.\n",
    "- `Projection Pushdown`: Only necessary columns are selected.\n",
    "- `Parallel Execution`: Uses multiple CPU cores for processing."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 22,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "shape: (500_000, 2)\n",
      "â”Œâ”€â”€â”€â”€â”€â”€â”€â”€â”¬â”€â”€â”€â”€â”€â”€â”€â”€â”€â”\n",
      "â”‚ id     â”† value   â”‚\n",
      "â”‚ ---    â”† ---     â”‚\n",
      "â”‚ i64    â”† i64     â”‚\n",
      "â•žâ•â•â•â•â•â•â•â•â•ªâ•â•â•â•â•â•â•â•â•â•¡\n",
      "â”‚ 1      â”† 1000000 â”‚\n",
      "â”‚ 2      â”† 999999  â”‚\n",
      "â”‚ 3      â”† 999998  â”‚\n",
      "â”‚ 4      â”† 999997  â”‚\n",
      "â”‚ 5      â”† 999996  â”‚\n",
      "â”‚ 6      â”† 999995  â”‚\n",
      "â”‚ 7      â”† 999994  â”‚\n",
      "â”‚ 8      â”† 999993  â”‚\n",
      "â”‚ 9      â”† 999992  â”‚\n",
      "â”‚ 10     â”† 999991  â”‚\n",
      "â”‚ 11     â”† 999990  â”‚\n",
      "â”‚ 12     â”† 999989  â”‚\n",
      "â”‚ 13     â”† 999988  â”‚\n",
      "â”‚ 14     â”† 999987  â”‚\n",
      "â”‚ 15     â”† 999986  â”‚\n",
      "â”‚ 16     â”† 999985  â”‚\n",
      "â”‚ 17     â”† 999984  â”‚\n",
      "â”‚ 18     â”† 999983  â”‚\n",
      "â”‚ 19     â”† 999982  â”‚\n",
      "â”‚ 20     â”† 999981  â”‚\n",
      "â”‚ â€¦      â”† â€¦       â”‚\n",
      "â”‚ 499981 â”† 500020  â”‚\n",
      "â”‚ 499982 â”† 500019  â”‚\n",
      "â”‚ 499983 â”† 500018  â”‚\n",
      "â”‚ 499984 â”† 500017  â”‚\n",
      "â”‚ 499985 â”† 500016  â”‚\n",
      "â”‚ 499986 â”† 500015  â”‚\n",
      "â”‚ 499987 â”† 500014  â”‚\n",
      "â”‚ 499988 â”† 500013  â”‚\n",
      "â”‚ 499989 â”† 500012  â”‚\n",
      "â”‚ 499990 â”† 500011  â”‚\n",
      "â”‚ 499991 â”† 500010  â”‚\n",
      "â”‚ 499992 â”† 500009  â”‚\n",
      "â”‚ 499993 â”† 500008  â”‚\n",
      "â”‚ 499994 â”† 500007  â”‚\n",
      "â”‚ 499995 â”† 500006  â”‚\n",
      "â”‚ 499996 â”† 500005  â”‚\n",
      "â”‚ 499997 â”† 500004  â”‚\n",
      "â”‚ 499998 â”† 500003  â”‚\n",
      "â”‚ 499999 â”† 500002  â”‚\n",
      "â”‚ 500000 â”† 500001  â”‚\n",
      "â””â”€â”€â”€â”€â”€â”€â”€â”€â”´â”€â”€â”€â”€â”€â”€â”€â”€â”€â”˜\n"
     ]
    }
   ],
   "source": [
    "# Large dataset simulation\n",
    "df = pl.DataFrame({\n",
    "    'id': range(1, 1000001),\n",
    "    'value': range(1000000, 0, -1)\n",
    "})\n",
    "\n",
    "# Convert to LazyFrame\n",
    "lf = df.lazy()\n",
    "\n",
    "# Apply filtering and selection\n",
    "optimized_query = (\n",
    "    lf\n",
    "    .filter(pl.col('value') > 500000)  # Predicate pushdown\n",
    "    .select(['id', 'value'])           # Projection pushdown\n",
    ")\n",
    "\n",
    "# Execute query\n",
    "result = optimized_query.collect()\n",
    "\n",
    "print(result)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### 3. Working with Large Datasets (>1GB)\n",
    "\n",
    "**When handling large datasets, you can:**\n",
    "- Use LazyFrame to avoid memory overload.\n",
    "- Read data in chunks to process it efficiently.\n",
    "- Use Parquet instead of CSV for better performance."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "shape: (41, 2)\n",
      "â”Œâ”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”¬â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”\n",
      "â”‚ product_name â”† total       â”‚\n",
      "â”‚ ---          â”† ---         â”‚\n",
      "â”‚ str          â”† str         â”‚\n",
      "â•žâ•â•â•â•â•â•â•â•â•â•â•â•â•â•â•ªâ•â•â•â•â•â•â•â•â•â•â•â•â•â•¡\n",
      "â”‚ audience     â”† 38046210.92 â”‚\n",
      "â”‚ another      â”† 17474981.56 â”‚\n",
      "â”‚ address      â”† 14218324.1  â”‚\n",
      "â”‚ entire       â”† 38224990.16 â”‚\n",
      "â”‚ occur        â”† 3866642.03  â”‚\n",
      "â”‚ â€¦            â”† â€¦           â”‚\n",
      "â”‚ lawyer       â”† 26325636.8  â”‚\n",
      "â”‚ those        â”† 31218022.61 â”‚\n",
      "â”‚ edge         â”† 1224929.09  â”‚\n",
      "â”‚ understand   â”† 29002473.18 â”‚\n",
      "â”‚ fire         â”† 29031814.68 â”‚\n",
      "â””â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”´â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”˜\n"
     ]
    }
   ],
   "source": [
    "# Deakling with a CSV of more than 1gb\n",
    "\n",
    "# Read CSV file lazily to avoid high memory usage\n",
    "lf = pl.scan_csv('../sales.csv')\n",
    "\n",
    "# Perform filtering and aggregation lazily\n",
    "query = (\n",
    "    lf.filter(pl.col('unit_price') > 900)\n",
    "    .group_by('product_name')\n",
    "    .agg(pl.col('unit_price').sum().alias('total'))\n",
    ")\n",
    "\n",
    "result = query.collect()\n",
    "\n",
    "result = result.with_columns(pl.col('total').round(2).cast(pl.Utf8))\n",
    "\n",
    "# .cast(pl.Utf8) to convert o string\n",
    "\n",
    "print(result)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### ðŸ“Œ Summary\n",
    "| Feature |\tRecommendation |\n",
    "| ------- | -------------- |\n",
    "| Small Datasets (<1GB) | Use pl.DataFrame |\n",
    "| Large Datasets (>1GB) | Use pl.LazyFrame with scan_csv or read_parquet |\n",
    "| Performance Optimization | Use Lazy Execution to enable optimizations |\n",
    "| File Formats | Prefer Parquet over CSV for large datasets |\n",
    "\n",
    "Polars' **parallel execution and lazy optimizations** make it ideal for handling large-scale data efficiently."
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": ".venv",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.12.8"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
