{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "!pip install polars"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 1,
   "metadata": {},
   "outputs": [],
   "source": [
    "import polars as pl"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Optimizations and Performance in Polars\n",
    "\n",
    "Polars is built for high-performance data manipulation, leveraging parallelism and lazy execution. In this section, we'll cover:\n",
    "\n",
    "- LazyFrame vs. DataFrame: When to Use Each?\n",
    "- Parallel Execution and Automatic Optimizations\n",
    "- Working with Large Datasets (>1GB)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### 1. LazyFrame vs. DataFrame: When to Use Each?\n",
    "Polars offers two main data structures:\n",
    "\n",
    "1. `pl.DataFrame` (Eager Execution)\n",
    "- Similar to Pandas.\n",
    "- Executes operations immediately.\n",
    "- Best for small to medium datasets when quick results are needed.\n",
    "\n",
    "2. `pl.LazyFrame` (Lazy Execution)\n",
    "- Similar to SQL query planners.\n",
    "- Operations are deferred and optimized before execution.\n",
    "- Best for large datasets where performance matters."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 24,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Eager Execution:\n",
      " shape: (3, 2)\n",
      "┌─────┬───────┐\n",
      "│ id  ┆ value │\n",
      "│ --- ┆ ---   │\n",
      "│ i64 ┆ i64   │\n",
      "╞═════╪═══════╡\n",
      "│ 3   ┆ 30    │\n",
      "│ 4   ┆ 40    │\n",
      "│ 5   ┆ 50    │\n",
      "└─────┴───────┘\n",
      "Lazy Execution (after collect()):\n",
      " shape: (3, 2)\n",
      "┌─────┬───────┐\n",
      "│ id  ┆ value │\n",
      "│ --- ┆ ---   │\n",
      "│ i64 ┆ i64   │\n",
      "╞═════╪═══════╡\n",
      "│ 3   ┆ 30    │\n",
      "│ 4   ┆ 40    │\n",
      "│ 5   ┆ 50    │\n",
      "└─────┴───────┘\n"
     ]
    }
   ],
   "source": [
    "df = pl.DataFrame({\n",
    "    'id': [1, 2, 3, 4, 5],\n",
    "    'value': [10, 20, 30, 40, 50]\n",
    "})\n",
    "\n",
    "# Applying a filter (Eager execution - runs immediately)\n",
    "eager_result = df.filter(pl.col('value') > 20)\n",
    "\n",
    "print('Eager Execution:\\n', eager_result)\n",
    "\n",
    "# ----------\n",
    "\n",
    "# Sample LazyFrame (Lazy Execution)\n",
    "lf = df.lazy()\n",
    "\n",
    "# Applying a filter (Lazy execution - does not run immediately)\n",
    "lazy_result = lf.filter(pl.col('value') > 20)\n",
    "\n",
    "# Must call collect() to execute LazyFrame\n",
    "final_result = lazy_result.collect()\n",
    "\n",
    "print('Lazy Execution (after collect()):\\n', final_result)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### 2. Parallel Execution and Automatic Optimizations\n",
    "\n",
    "Polars is designed for multi-threading and automatically optimizes queries.\n",
    "\n",
    "**Polars' Optimization Techniques**\n",
    "- `Predicate Pushdown`: Filters are applied early to reduce computation.\n",
    "- `Projection Pushdown`: Only necessary columns are selected.\n",
    "- `Parallel Execution`: Uses multiple CPU cores for processing."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 22,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "shape: (500_000, 2)\n",
      "┌────────┬─────────┐\n",
      "│ id     ┆ value   │\n",
      "│ ---    ┆ ---     │\n",
      "│ i64    ┆ i64     │\n",
      "╞════════╪═════════╡\n",
      "│ 1      ┆ 1000000 │\n",
      "│ 2      ┆ 999999  │\n",
      "│ 3      ┆ 999998  │\n",
      "│ 4      ┆ 999997  │\n",
      "│ 5      ┆ 999996  │\n",
      "│ 6      ┆ 999995  │\n",
      "│ 7      ┆ 999994  │\n",
      "│ 8      ┆ 999993  │\n",
      "│ 9      ┆ 999992  │\n",
      "│ 10     ┆ 999991  │\n",
      "│ 11     ┆ 999990  │\n",
      "│ 12     ┆ 999989  │\n",
      "│ 13     ┆ 999988  │\n",
      "│ 14     ┆ 999987  │\n",
      "│ 15     ┆ 999986  │\n",
      "│ 16     ┆ 999985  │\n",
      "│ 17     ┆ 999984  │\n",
      "│ 18     ┆ 999983  │\n",
      "│ 19     ┆ 999982  │\n",
      "│ 20     ┆ 999981  │\n",
      "│ …      ┆ …       │\n",
      "│ 499981 ┆ 500020  │\n",
      "│ 499982 ┆ 500019  │\n",
      "│ 499983 ┆ 500018  │\n",
      "│ 499984 ┆ 500017  │\n",
      "│ 499985 ┆ 500016  │\n",
      "│ 499986 ┆ 500015  │\n",
      "│ 499987 ┆ 500014  │\n",
      "│ 499988 ┆ 500013  │\n",
      "│ 499989 ┆ 500012  │\n",
      "│ 499990 ┆ 500011  │\n",
      "│ 499991 ┆ 500010  │\n",
      "│ 499992 ┆ 500009  │\n",
      "│ 499993 ┆ 500008  │\n",
      "│ 499994 ┆ 500007  │\n",
      "│ 499995 ┆ 500006  │\n",
      "│ 499996 ┆ 500005  │\n",
      "│ 499997 ┆ 500004  │\n",
      "│ 499998 ┆ 500003  │\n",
      "│ 499999 ┆ 500002  │\n",
      "│ 500000 ┆ 500001  │\n",
      "└────────┴─────────┘\n"
     ]
    }
   ],
   "source": [
    "# Large dataset simulation\n",
    "df = pl.DataFrame({\n",
    "    'id': range(1, 1000001),\n",
    "    'value': range(1000000, 0, -1)\n",
    "})\n",
    "\n",
    "# Convert to LazyFrame\n",
    "lf = df.lazy()\n",
    "\n",
    "# Apply filtering and selection\n",
    "optimized_query = (\n",
    "    lf\n",
    "    .filter(pl.col('value') > 500000)  # Predicate pushdown\n",
    "    .select(['id', 'value'])           # Projection pushdown\n",
    ")\n",
    "\n",
    "# Execute query\n",
    "result = optimized_query.collect()\n",
    "\n",
    "print(result)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### 3. Working with Large Datasets (>1GB)\n",
    "\n",
    "**When handling large datasets, you can:**\n",
    "- Use LazyFrame to avoid memory overload.\n",
    "- Read data in chunks to process it efficiently.\n",
    "- Use Parquet instead of CSV for better performance."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 21,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "shape: (50, 2)\n",
      "┌───────────┬─────────────┐\n",
      "│ product   ┆ total       │\n",
      "│ ---       ┆ ---         │\n",
      "│ str       ┆ str         │\n",
      "╞═══════════╪═════════════╡\n",
      "│ enter     ┆ 19220181.75 │\n",
      "│ happy     ┆ 19349138.12 │\n",
      "│ apply     ┆ 19041936.07 │\n",
      "│ would     ┆ 19214605.68 │\n",
      "│ cold      ┆ 19350622.0  │\n",
      "│ floor     ┆ 19146144.96 │\n",
      "│ important ┆ 19165248.78 │\n",
      "│ charge    ┆ 18806296.98 │\n",
      "│ church    ┆ 19508403.31 │\n",
      "│ certain   ┆ 18976284.17 │\n",
      "│ whom      ┆ 19321754.75 │\n",
      "│ speak     ┆ 18944193.08 │\n",
      "│ least     ┆ 19525448.62 │\n",
      "│ reason    ┆ 19389997.12 │\n",
      "│ but       ┆ 19201797.88 │\n",
      "│ half      ┆ 19123176.29 │\n",
      "│ what      ┆ 19118490.49 │\n",
      "│ long      ┆ 19102148.33 │\n",
      "│ budget    ┆ 19158962.61 │\n",
      "│ place     ┆ 19102064.75 │\n",
      "│ …         ┆ …           │\n",
      "│ service   ┆ 19263025.68 │\n",
      "│ water     ┆ 19332875.84 │\n",
      "│ bit       ┆ 19039997.64 │\n",
      "│ figure    ┆ 19199389.04 │\n",
      "│ that      ┆ 19110237.85 │\n",
      "│ employee  ┆ 19254682.0  │\n",
      "│ fly       ┆ 18975999.31 │\n",
      "│ then      ┆ 19357373.76 │\n",
      "│ health    ┆ 19100247.42 │\n",
      "│ save      ┆ 19126413.06 │\n",
      "│ professor ┆ 18992763.7  │\n",
      "│ include   ┆ 19425897.27 │\n",
      "│ evening   ┆ 19084404.1  │\n",
      "│ seek      ┆ 19359871.8  │\n",
      "│ across    ┆ 19207218.98 │\n",
      "│ politics  ┆ 19202566.09 │\n",
      "│ about     ┆ 19138885.85 │\n",
      "│ political ┆ 19288300.59 │\n",
      "│ this      ┆ 19102613.67 │\n",
      "│ better    ┆ 19214311.29 │\n",
      "└───────────┴─────────────┘\n"
     ]
    }
   ],
   "source": [
    "# Deakling with a CSV of more than 1gb\n",
    "\n",
    "# Read CSV file lazily to avoid high memory usage\n",
    "lf = pl.scan_csv('sales.csv')\n",
    "\n",
    "# Perform filtering and aggregation lazily\n",
    "query = (\n",
    "    lf.filter(pl.col('sale_price') > 900)\n",
    "    .group_by('product')\n",
    "    .agg(pl.col('sale_price').sum().alias('total'))\n",
    ")\n",
    "\n",
    "result = query.collect()\n",
    "\n",
    "result = result.with_columns(pl.col('total').round(2).cast(pl.Utf8))\n",
    "\n",
    "# .cast(pl.Utf8) to convert o string\n",
    "\n",
    "print(result)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### 📌 Summary\n",
    "| Feature |\tRecommendation |\n",
    "| ------- | -------------- |\n",
    "| Small Datasets (<1GB) | Use pl.DataFrame |\n",
    "| Large Datasets (>1GB) | Use pl.LazyFrame with scan_csv or read_parquet |\n",
    "| Performance Optimization | Use Lazy Execution to enable optimizations |\n",
    "| File Formats | Prefer Parquet over CSV for large datasets |\n",
    "\n",
    "Polars' **parallel execution and lazy optimizations** make it ideal for handling large-scale data efficiently."
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": ".venv",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.12.8"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
