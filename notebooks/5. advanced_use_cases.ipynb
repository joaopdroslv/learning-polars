{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "!pip install polars"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "metadata": {},
   "outputs": [],
   "source": [
    "import polars as pl"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### 1. SQL Integration (pl.SQLContext)\n",
    "\n",
    "Polars provides SQL support, allowing you to run SQL queries directly on `DataFrame` objects.\n",
    "\n",
    "**Example: Using SQL in Polars**"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "shape: (2, 2)\n",
      "â”Œâ”€â”€â”€â”€â”€â”€â”€â”¬â”€â”€â”€â”€â”€â”\n",
      "â”‚ name  â”† age â”‚\n",
      "â”‚ ---   â”† --- â”‚\n",
      "â”‚ str   â”† i64 â”‚\n",
      "â•žâ•â•â•â•â•â•â•â•ªâ•â•â•â•â•â•¡\n",
      "â”‚ David â”† 40  â”‚\n",
      "â”‚ Eve   â”† 45  â”‚\n",
      "â””â”€â”€â”€â”€â”€â”€â”€â”´â”€â”€â”€â”€â”€â”˜\n"
     ]
    }
   ],
   "source": [
    "df = pl.DataFrame({\n",
    "    'id': [1, 2, 3, 4, 5],\n",
    "    'name': ['Alice', 'Bob', 'Charlie', 'David', 'Eve'],\n",
    "    'age': [25, 30, 35, 40, 45]\n",
    "})\n",
    "\n",
    "# Create SQLContext and register the DataFrame\n",
    "sql_context = pl.SQLContext()\n",
    "sql_context.register('people', df)\n",
    "\n",
    "# Run SQL Query\n",
    "result = sql_context.execute('SELECT name, age FROM people WHERE age > 35')\n",
    "\n",
    "print(result.collect())"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "**Why Use SQL with Polars?**\n",
    "- Great for users familiar with SQL.\n",
    "- Useful for migrating existing SQL-based workflows.\n",
    "- Combines well with Polars' performance optimizations."
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### 2. Working with Nested JSON Data\n",
    "\n",
    "Polars natively supports working with complex JSON structures, making it ideal for handling APIs and semi-structured data.\n",
    "\n",
    "**Example: Parsing Nested JSON**"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "shape: (3, 4)\n",
      "â”Œâ”€â”€â”€â”€â”€â”¬â”€â”€â”€â”€â”€â”€â”€â”€â”€â”¬â”€â”€â”€â”€â”€â”¬â”€â”€â”€â”€â”€â”€â”\n",
      "â”‚ id  â”† name    â”† age â”† city â”‚\n",
      "â”‚ --- â”† ---     â”† --- â”† ---  â”‚\n",
      "â”‚ i64 â”† str     â”† i64 â”† str  â”‚\n",
      "â•žâ•â•â•â•â•â•ªâ•â•â•â•â•â•â•â•â•â•ªâ•â•â•â•â•â•ªâ•â•â•â•â•â•â•¡\n",
      "â”‚ 1   â”† Alice   â”† 25  â”† NY   â”‚\n",
      "â”‚ 2   â”† Bob     â”† 30  â”† LA   â”‚\n",
      "â”‚ 3   â”† Charlie â”† 35  â”† SF   â”‚\n",
      "â””â”€â”€â”€â”€â”€â”´â”€â”€â”€â”€â”€â”€â”€â”€â”€â”´â”€â”€â”€â”€â”€â”´â”€â”€â”€â”€â”€â”€â”˜\n"
     ]
    }
   ],
   "source": [
    "json_data = [\n",
    "    {'id': 1, 'name': 'Alice', 'info': {'age': 25, 'city': 'NY'}},\n",
    "    {'id': 2, 'name': 'Bob', 'info': {'age': 30, 'city': 'LA'}},\n",
    "    {'id': 3, 'name': 'Charlie', 'info': {'age': 35, 'city': 'SF'}}\n",
    "]\n",
    "\n",
    "# Convert JSON to DataFrame\n",
    "df = pl.from_dicts(json_data)\n",
    "\n",
    "# Extract nested fields\n",
    "df = df.with_columns(\n",
    "    pl.col('info').struct.field('age').alias('age'),\n",
    "    pl.col('info').struct.field('city').alias('city')\n",
    ").drop('info')\n",
    "\n",
    "print(df)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "**Why Use Polars for JSON?**\n",
    "- Supports deep field extraction (`struct.field`).\n",
    "- Handles large JSON files efficiently with `scan_json()`."
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### 3. Creating Custom Functions (`apply`, `map`)\n",
    "\n",
    "Polars allows custom transformations using apply and map for column-wise operations."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "shape: (4, 3)\n",
      "â”Œâ”€â”€â”€â”€â”€â”€â”€â”€â”€â”¬â”€â”€â”€â”€â”€â”€â”€â”¬â”€â”€â”€â”€â”€â”€â”€â”\n",
      "â”‚ name    â”† score â”† grade â”‚\n",
      "â”‚ ---     â”† ---   â”† ---   â”‚\n",
      "â”‚ str     â”† i64   â”† str   â”‚\n",
      "â•žâ•â•â•â•â•â•â•â•â•â•ªâ•â•â•â•â•â•â•â•ªâ•â•â•â•â•â•â•â•¡\n",
      "â”‚ Alice   â”† 85    â”† B     â”‚\n",
      "â”‚ Bob     â”† 92    â”† A     â”‚\n",
      "â”‚ Charlie â”† 78    â”† C     â”‚\n",
      "â”‚ Erick   â”† 61    â”† C     â”‚\n",
      "â””â”€â”€â”€â”€â”€â”€â”€â”€â”€â”´â”€â”€â”€â”€â”€â”€â”€â”´â”€â”€â”€â”€â”€â”€â”€â”˜\n"
     ]
    }
   ],
   "source": [
    "df = pl.DataFrame({\n",
    "    'name': ['Alice', 'Bob', 'Charlie', 'Erick'],\n",
    "    'score': [85, 92, 78, 61]\n",
    "})\n",
    "\n",
    "# Custom function to grade scores\n",
    "def grade(score):\n",
    "    return 'A' if score >= 90 else 'B' if score >= 80 else 'C'\n",
    "\n",
    "# Apply custom function\n",
    "df = df.with_columns(\n",
    "    pl.col('score').map_elements(grade, return_dtype=pl.Utf8).alias('grade')\n",
    ")\n",
    "\n",
    "print(df)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### 4. Using Polars in ETL and Data Pipelines\n",
    "\n",
    "Polars is great for **ETL (Extract, Transform, Load)** processes due to its speed and memory efficiency.\n",
    "\n",
    "**Example: ETL Pipeline in Polars**"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Extract: Load large dataset lazily\n",
    "lf = pl.scan_csv('../sales.csv')\n",
    "\n",
    "# Transform: Filter and aggregate\n",
    "lf_transformed = (\n",
    "    lf.group_by('product')\n",
    "    .agg((pl.col('sale_price') * pl.col('units_sold')).alias('total'))\n",
    ")\n",
    "\n",
    "# Load: Save as Parquet for efficient storage\n",
    "lf_transformed.collect().write_parquet('../sales_summary.parquet')"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "**Why Use Polars for ETL?**\n",
    "- `Lazy execution` optimizes performance.\n",
    "- `Parquet format` reduces storage size.\n",
    "- `Parallel execution` speeds up transformations."
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### ðŸ“Œ Summary\n",
    "\n",
    "| Feature |\tBenefit |\n",
    "| ------- | ------- |\n",
    "| SQL Integration (pl.SQLContext) |\tUse SQL queries on DataFrames |\n",
    "| Nested JSON Handling | Easily extract and transform complex JSON structures |\n",
    "| Custom Functions (apply, map) | Apply row-wise or vectorized transformations |\n",
    "| ETL & Data Pipelines | Process large datasets efficiently |\n",
    "\n",
    "Polars is a **high-performance alternative** to Pandas, perfect for handling large-scale **data processing and ETL workflows.** ðŸš€"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": ".venv",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.12.8"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
